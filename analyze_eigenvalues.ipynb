{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "import pysta\n",
    "import stc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_name', 'stim', 'spike_train', 'info']\n",
      "(64, 9000)\n",
      "(156, 9000)\n",
      "{'channel_names': ['ch_12a', 'ch_12b', 'ch_12c', 'ch_13a', 'ch_13b', 'ch_13c', 'ch_13d', 'ch_13e', 'ch_14a', 'ch_14b', 'ch_14c', 'ch_14d', 'ch_16a', 'ch_16b', 'ch_16c', 'ch_17a', 'ch_17b', 'ch_17c', 'ch_17d', 'ch_21a', 'ch_21b', 'ch_21c', 'ch_21d', 'ch_21e', 'ch_22a', 'ch_22b', 'ch_23a', 'ch_23b', 'ch_23c', 'ch_23d', 'ch_25a', 'ch_25b', 'ch_25c', 'ch_26a', 'ch_26b', 'ch_26c', 'ch_26d', 'ch_27a', 'ch_27b', 'ch_27c', 'ch_27d', 'ch_28a', 'ch_28b', 'ch_28c', 'ch_31a', 'ch_31b', 'ch_31c', 'ch_31d', 'ch_32a', 'ch_32b', 'ch_32c', 'ch_33a', 'ch_33b', 'ch_33c', 'ch_33d', 'ch_35a', 'ch_35b', 'ch_35c', 'ch_35d', 'ch_35e', 'ch_35f', 'ch_35g', 'ch_36a', 'ch_36b', 'ch_36c', 'ch_36d', 'ch_37a', 'ch_37b', 'ch_37c', 'ch_37d', 'ch_37e', 'ch_38a', 'ch_41a', 'ch_41b', 'ch_41c', 'ch_41d', 'ch_42a', 'ch_42b', 'ch_42c', 'ch_43a', 'ch_43b', 'ch_43c', 'ch_45a', 'ch_45b', 'ch_45c', 'ch_46a', 'ch_46b', 'ch_47a', 'ch_48a', 'ch_48b', 'ch_48c', 'ch_48d', 'ch_48e', 'ch_51a', 'ch_51b', 'ch_53a', 'ch_53b', 'ch_53c', 'ch_53d', 'ch_54a', 'ch_54b', 'ch_54c', 'ch_54d', 'ch_56a', 'ch_56b', 'ch_58a', 'ch_61a', 'ch_61b', 'ch_62a', 'ch_62b', 'ch_63a', 'ch_63b', 'ch_63c', 'ch_63d', 'ch_63e', 'ch_64a', 'ch_65a', 'ch_65b', 'ch_65c', 'ch_68a', 'ch_68b', 'ch_71a', 'ch_71b', 'ch_71c', 'ch_72a', 'ch_72b', 'ch_72c', 'ch_72d', 'ch_72e', 'ch_73a', 'ch_73b', 'ch_73c', 'ch_74a', 'ch_74b', 'ch_74c', 'ch_74d', 'ch_75a', 'ch_76a', 'ch_76b', 'ch_76c', 'ch_77a', 'ch_82a', 'ch_82b', 'ch_82c', 'ch_83a', 'ch_83b', 'ch_83c', 'ch_85a', 'ch_85b', 'ch_86a', 'ch_86b', 'ch_86c', 'ch_86d', 'ch_87a', 'ch_87b', 'ch_87c'], 'sampling_rate': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "data_folder_name = \"data\"\n",
    "\n",
    "# load stim and spike data\n",
    "# dataset_name = \"20180618\"\n",
    "# dataset_name = \"20180621\"\n",
    "dataset_name = \"20180626\"\n",
    "# dataset_name = \"20180828\"\n",
    "\n",
    "stim, spike_train, info = pysta.load_data(dataset_name, data_folder_name)\n",
    "\n",
    "# dataset_filename = \"data/{}.mat\".format(dataset_name)\n",
    "# stim, spike_train, info = pysta.load_data_mat(dataset_filename)\n",
    "\n",
    "channel_names = [ch.replace(\"ch_\",\"\") for ch in info[\"channel_names\"]]\n",
    "# info[\"channel_names\"]\n",
    "\n",
    "# load cell type\n",
    "cell_types = pd.read_csv(\"{}/{}_cell_type.csv\".format(data_folder_name, dataset_name))\n",
    "# cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc number of spikes\n",
    "tap = 8 # -700 ms ~ 0\n",
    "\n",
    "num_samples = list()\n",
    "for idx in range(spike_train.shape[0]):    \n",
    "    spike_triggered_stim, spike_count = pysta.grab_spike_triggered_stim(stim, spike_train[idx], tap)\n",
    "    num_samples.append(spike_triggered_stim.shape[0])\n",
    "\n",
    "num_samples_df = pd.DataFrame({\"channel_name\": channel_names, \"number_of_samples\": num_samples})\n",
    "# num_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the effect of smoothing on the largest eigenvalue($\\lambda_1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read eigenvalues\n",
    "\n",
    "# helper function\n",
    "def read_eigen_values(folder_name, channel_names):\n",
    "    all_eig_values = dict()\n",
    "    largest_eig_values = list()\n",
    "\n",
    "    for channel_name in channel_names:\n",
    "        filename = \"{}/ch_{}_eig_val.txt\".format(folder_name,channel_name)\n",
    "        eig_val = np.loadtxt(filename)\n",
    "\n",
    "        all_eig_values[channel_name] = eig_val\n",
    "    #     eigen_values.append(eig_val)\n",
    "        largest_eig_values.append(eig_val[0])\n",
    "    return all_eig_values, largest_eig_values\n",
    "    \n",
    "\n",
    "folder_name = \"{}_stc_tap{}\".format(dataset_name,tap)\n",
    "all_eig_values, largest_eig_values = read_eigen_values(folder_name, channel_names)\n",
    "# convert to DataFrame\n",
    "result_eig = pd.DataFrame({\"channel_name\": channel_names, \"largest_eig_values\":largest_eig_values})\n",
    "\n",
    "folder_name = \"{}_stc_tap{}_smoothed\".format(dataset_name,tap)\n",
    "all_eig_values, largest_eig_values = read_eigen_values(folder_name, channel_names)\n",
    "# convert to DataFrame\n",
    "result_eig_smoothed = pd.DataFrame({\"channel_name\": channel_names, \"largest_eig_values\":largest_eig_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(121)\n",
    "result_eig[\"largest_eig_values\"].hist(alpha=0.75)\n",
    "result_eig_smoothed[\"largest_eig_values\"].hist(alpha=0.75)\n",
    "plt.grid(\"off\")\n",
    "plt.xlabel(\"$\\lambda_1$\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "plt.legend([\"no smoothing\", \"smoothed\"])\n",
    "\n",
    "plt.subplot(122)\n",
    "# merge with num_samples\n",
    "num_samples_eig = num_samples_df.merge(result_eig)\n",
    "num_samples_eig_smoothed = num_samples_df.merge(result_eig_smoothed)\n",
    "\n",
    "plt.scatter(num_samples_eig[\"number_of_samples\"], num_samples_eig[\"largest_eig_values\"])\n",
    "plt.scatter(num_samples_eig_smoothed[\"number_of_samples\"], num_samples_eig_smoothed[\"largest_eig_values\"])\n",
    "plt.xlabel('number of samples')\n",
    "plt.ylabel('$\\lambda_1$')\n",
    "plt.xlim(0,plt.xlim()[1])\n",
    "plt.ylim(0,plt.ylim()[1])\n",
    "\n",
    "\n",
    "plt.legend([\"no-smoothing\", \"smoothed\"])\n",
    "# see https://arxiv.org/pdf/0901.3245.pdf to understand the effect of # samples on the largest eigenvalue\n",
    "\n",
    "plt.savefig(\"eig_smoothed_{}.pdf\".format(dataset_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's optimize the spatial smoothing parameter $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
